Test Error: 
 Accuracy: 35.6%, Avg loss:      nan 

Test Error: 
 Accuracy: 35.6%, Avg loss:      nan 

Test Error: 
 Accuracy: 35.6%, Avg loss:      nan 

[[1262    0    0    0    0    0    0    0]
 [ 928    0    0    0    0    0    0    0]
 [ 444    0    0    0    0    0    0    0]
 [ 444    0    0    0    0    0    0    0]
 [ 325    0    0    0    0    0    0    0]
 [  23    0    0    0    0    0    0    0]
 [  93    0    0    0    0    0    0    0]
 [  27    0    0    0    0    0    0    0]]
Epoch 1
-------------------------------

Epoch 1
-------------------------------

Epoch 1
-------------------------------

Epoch 1
-------------------------------

Epoch 1
-------------------------------

Epoch 1
-------------------------------

Epoch 1
-------------------------------

Epoch 1
-------------------------------

Epoch 1
-------------------------------

Epoch 1
-------------------------------

Epoch 1
-------------------------------

Epoch 1
-------------------------------

Epoch 1
-------------------------------

Epoch 1
-------------------------------

batch:100    loss: 1.734965 lr: 0.001

batch:200    loss: 1.723235 lr: 0.001

batch:300    loss: 1.704523 lr: 0.001

batch:400    loss: 1.688820 lr: 0.001

batch:500    loss: 1.666727 lr: 0.001

batch:600    loss: 1.639328 lr: 0.001

batch:700    loss: 1.612593 lr: 0.001

batch:800    loss: 1.587406 lr: 0.001

batch:900    loss: 1.565930 lr: 0.001

Epoch 1
-------------------------------

batch:100    loss: 1.693949 lr: 0.001

batch:200    loss: 1.647444 lr: 0.001

batch:300    loss: 1.634862 lr: 0.001

batch:400    loss: 1.623081 lr: 0.001

batch:500    loss: 1.612960 lr: 0.001

batch:600    loss: 1.605611 lr: 0.001

Epoch 1
-------------------------------

batch:100    loss: 1.622716 lr: 0.001

batch:200    loss: 1.616941 lr: 0.001

batch:300    loss: 1.594997 lr: 0.001

batch:400    loss: 1.573708 lr: 0.001

batch:500    loss: 1.565669 lr: 0.001

batch:600    loss: 1.562396 lr: 0.001

batch:700    loss: 1.552795 lr: 0.001

batch:800    loss: 1.543596 lr: 0.001

Epoch 1
-------------------------------

Epoch 1
-------------------------------

batch:100    loss: 1.648296 lr: 0.001

batch:200    loss: 1.620454 lr: 0.001

batch:300    loss: 1.613807 lr: 0.001

batch:400    loss: 1.606479 lr: 0.001

batch:500    loss: 1.601319 lr: 0.001

batch:600    loss: 1.596916 lr: 0.001

batch:700    loss: 1.591212 lr: 0.001

batch:800    loss: 1.589326 lr: 0.001

Epoch 1
-------------------------------

batch:100    loss: 1.679044 lr: 0.001

batch:200    loss: 1.631405 lr: 0.001

batch:300    loss: 1.610867 lr: 0.001

Epoch 1
-------------------------------

batch:100    loss: 1.692041 lr: 0.001

batch:200    loss: 1.640503 lr: 0.001

batch:300    loss: 1.620471 lr: 0.001

batch:400    loss: 1.613841 lr: 0.001

batch:500    loss: 1.590442 lr: 0.001

batch:600    loss: 1.565102 lr: 0.001

batch:700    loss: 1.541306 lr: 0.001

batch:800    loss: 1.519077 lr: 0.001

Test Error: 
 Accuracy: 50.2%, Avg loss: 1.428324 

[[1154  205    0    0    0    0    0]
 [ 289  610    1    0    0    0    0]
 [ 373   49   34    0    5    0    0]
 [ 329   93    0    0    1    0    0]
 [ 247   74    1    0    0    0    0]
 [  30    8    0    0    1    0    0]
 [  57   17    0    0    1    0    0]]
Saved PyTorch Model State epoch is 0   correct = 50.2374965074043

Epoch 2
-------------------------------

batch:100    loss: 1.260492 lr: 0.0009998026241462927

batch:200    loss: 1.263803 lr: 0.0009998026241462927

batch:300    loss: 1.259470 lr: 0.0009998026241462927

batch:400    loss: 1.239204 lr: 0.0009998026241462927

batch:500    loss: 1.224460 lr: 0.0009998026241462927

batch:600    loss: 1.207038 lr: 0.0009998026241462927

batch:700    loss: 1.198424 lr: 0.0009998026241462927

batch:800    loss: 1.189862 lr: 0.0009998026241462927

Test Error: 
 Accuracy: 63.8%, Avg loss: 1.052294 

[[1184   71   78    0   26    0    0]
 [ 183  661   39    0   17    0    0]
 [  86   15  355    0    5    0    0]
 [ 297   62   28    0   36    0    0]
 [ 159   44   36    0   83    0    0]
 [  25    4    2    0    8    0    0]
 [  24    6   40    0    5    0    0]]
Saved PyTorch Model State epoch is 1   correct = 63.788767812238056

Epoch 3
-------------------------------

batch:100    loss: 1.087631 lr: 0.0009992106913713087

batch:200    loss: 1.068172 lr: 0.0009992106913713087

batch:300    loss: 1.059424 lr: 0.0009992106913713087

batch:400    loss: 1.047203 lr: 0.0009992106913713087

batch:500    loss: 1.035168 lr: 0.0009992106913713087

batch:600    loss: 1.031724 lr: 0.0009992106913713087

batch:700    loss: 1.025254 lr: 0.0009992106913713087

batch:800    loss: 1.035034 lr: 0.0009992106913713087

Test Error: 
 Accuracy: 66.2%, Avg loss: 1.011236 

[[1156  110   80    1   12    0    0]
 [  99  772   20    0    9    0    0]
 [  66   21  366    0    8    0    0]
 [ 288   92   26    1   16    0    0]
 [ 136   58   54    0   74    0    0]
 [  25    5    3    0    6    0    0]
 [  17   11   43    0    4    0    0]]
Saved PyTorch Model State epoch is 2   correct = 66.19167365185807

Epoch 4
-------------------------------

batch:100    loss: 1.040238 lr: 0.0009982247858412322

batch:200    loss: 1.020824 lr: 0.0009982247858412322

batch:300    loss: 1.005134 lr: 0.0009982247858412322

batch:400    loss: 0.996409 lr: 0.0009982247858412322

batch:500    loss: 0.987058 lr: 0.0009982247858412322

batch:600    loss: 0.979279 lr: 0.0009982247858412322

batch:700    loss: 0.972541 lr: 0.0009982247858412322

batch:800    loss: 0.970396 lr: 0.0009982247858412322

Test Error: 
 Accuracy: 68.7%, Avg loss: 0.898871 

[[1227   60   37   19   16    0    0]
 [ 112  753   16    4   15    0    0]
 [  84   20  341    0   16    0    0]
 [ 304   68   14   18   19    0    0]
 [ 110   48   28   16  120    0    0]
 [  16    5    1    7   10    0    0]
 [  21   11   35    1    7    0    0]]
Saved PyTorch Model State epoch is 3   correct = 68.70634255378597

Epoch 5
-------------------------------

batch:100    loss: 0.911167 lr: 0.0009968458805257913

batch:200    loss: 0.920071 lr: 0.0009968458805257913

batch:300    loss: 0.935017 lr: 0.0009968458805257913

batch:400    loss: 0.945045 lr: 0.0009968458805257913

batch:500    loss: 0.949431 lr: 0.0009968458805257913

batch:600    loss: 0.971045 lr: 0.0009968458805257913

batch:700    loss: 0.979581 lr: 0.0009968458805257913

batch:800    loss: 0.980823 lr: 0.0009968458805257913

Test Error: 
 Accuracy: 67.3%, Avg loss: 0.950390 

[[1219   53   25   29   33    0    0]
 [  95  764    8   17   16    0    0]
 [  95   29  321    1   15    0    0]
 [ 285   72   10   29   27    0    0]
 [ 131   64   30   20   77    0    0]
 [  21    5    0   11    2    0    0]
 [  22   13   35    0    5    0    0]]
Epoch 6
-------------------------------

batch:100    loss: 0.978614 lr: 0.0009950753362380552

batch:200    loss: 1.051850 lr: 0.0009950753362380552

batch:300    loss: 1.037554 lr: 0.0009950753362380552

batch:400    loss: 1.040127 lr: 0.0009950753362380552

batch:500    loss: 1.024474 lr: 0.0009950753362380552

batch:600    loss: 1.018451 lr: 0.0009950753362380552

batch:700    loss: 1.007030 lr: 0.0009950753362380552

batch:800    loss: 0.994850 lr: 0.0009950753362380552

Test Error: 
 Accuracy: 68.7%, Avg loss: 0.904695 

[[1264   45   31   11    8    0    0]
 [ 127  740   16    9    8    0    0]
 [  76   18  357    2    8    0    0]
 [ 338   37    5   20   23    0    0]
 [ 160   33   34   16   79    0    0]
 [  22    1    2    7    7    0    0]
 [  21    7   42    1    4    0    0]]
Saved PyTorch Model State epoch is 5   correct = 68.73428331936296

Epoch 7
-------------------------------

batch:100    loss: 0.882034 lr: 0.0009929149002914756

batch:200    loss: 0.902142 lr: 0.0009929149002914756

batch:300    loss: 0.907121 lr: 0.0009929149002914756

batch:400    loss: 0.900321 lr: 0.0009929149002914756

batch:500    loss: 0.896534 lr: 0.0009929149002914756

batch:600    loss: 0.893057 lr: 0.0009929149002914756

batch:700    loss: 0.890191 lr: 0.0009929149002914756

batch:800    loss: 0.888707 lr: 0.0009929149002914756

Test Error: 
 Accuracy: 69.9%, Avg loss: 0.879988 

[[1290   46    5    7   11    0    0]
 [  97  776    6    8   13    0    0]
 [ 124   20  301    0   16    0    0]
 [ 332   40    1   15   35    0    0]
 [ 129   44   22    7  120    0    0]
 [  26    3    0    2    8    0    0]
 [  39   10   20    0    6    0    0]]
Saved PyTorch Model State epoch is 6   correct = 69.90779547359598

Epoch 8
-------------------------------

batch:100    loss: 0.838680 lr: 0.000990366704775499

batch:200    loss: 0.854082 lr: 0.000990366704775499

batch:300    loss: 0.853883 lr: 0.000990366704775499

batch:400    loss: 0.849322 lr: 0.000990366704775499

batch:500    loss: 0.849008 lr: 0.000990366704775499

batch:600    loss: 0.843664 lr: 0.000990366704775499

batch:700    loss: 0.842786 lr: 0.000990366704775499

batch:800    loss: 0.836443 lr: 0.000990366704775499

Test Error: 
 Accuracy: 70.6%, Avg loss: 0.848485 

[[1181   22   23   88   45    0    0]
 [  86  719   16   31   48    0    0]
 [  69    7  358    3   24    0    0]
 [ 244   26    5   84   64    0    0]
 [  78    8   24   26  186    0    0]
 [   9    0    0    8   22    0    0]
 [  26    5   34    0   10    0    0]]
Saved PyTorch Model State epoch is 7   correct = 70.63425537859737

Epoch 9
-------------------------------

batch:100    loss: 0.812162 lr: 0.0009874332644514525

batch:200    loss: 0.820054 lr: 0.0009874332644514525

batch:300    loss: 0.812390 lr: 0.0009874332644514525

batch:400    loss: 0.821891 lr: 0.0009874332644514525

batch:500    loss: 0.833599 lr: 0.0009874332644514525

batch:600    loss: 0.831365 lr: 0.0009874332644514525

batch:700    loss: 0.824160 lr: 0.0009874332644514525

batch:800    loss: 0.821594 lr: 0.0009874332644514525

Test Error: 
 Accuracy: 70.7%, Avg loss: 0.864636 

[[1182   71   50   50    6    0    0]
 [  66  770   27   21   16    0    0]
 [  57    9  386    2    7    0    0]
 [ 265   56    6   70   26    0    0]
 [ 107   33   39   22  121    0    0]
 [  16    4    1    4   14    0    0]
 [  17    4   47    1    6    0    0]]
Saved PyTorch Model State epoch is 8   correct = 70.66219614417435

Epoch 10
-------------------------------

batch:100    loss: 0.751358 lr: 0.0009841174742707772

batch:200    loss: 0.750609 lr: 0.0009841174742707772

batch:300    loss: 0.768049 lr: 0.0009841174742707772

batch:400    loss: 0.771849 lr: 0.0009841174742707772

batch:500    loss: 0.772776 lr: 0.0009841174742707772

batch:600    loss: 0.769813 lr: 0.0009841174742707772

batch:700    loss: 0.774557 lr: 0.0009841174742707772

batch:800    loss: 0.773733 lr: 0.0009841174742707772

Test Error: 
 Accuracy: 69.6%, Avg loss: 0.864082 

[[1088   33   31  105  102    0    0]
 [  98  719   18   45   20    0    0]
 [  55   15  360    3   28    0    0]
 [ 184   27    4  134   74    0    0]
 [  62   27   23   21  189    0    0]
 [   6    0    0    8   25    0    0]
 [  16    4   38    2   15    0    0]]
Epoch 11
-------------------------------

batch:100    loss: 0.734634 lr: 0.0009804226065180616

batch:200    loss: 0.746817 lr: 0.0009804226065180616

batch:300    loss: 0.756626 lr: 0.0009804226065180616

batch:400    loss: 0.759501 lr: 0.0009804226065180616

batch:500    loss: 0.757291 lr: 0.0009804226065180616

batch:600    loss: 0.758660 lr: 0.0009804226065180616

batch:700    loss: 0.753906 lr: 0.0009804226065180616

batch:800    loss: 0.761611 lr: 0.0009804226065180616

Test Error: 
 Accuracy: 72.3%, Avg loss: 0.800106 

[[1214   58   19   50   18    0    0]
 [  71  804    5   10   10    0    0]
 [  63   30  342    0   26    0    0]
 [ 265   50    1   84   23    0    0]
 [  99   43   22   13  145    0    0]
 [   8    3    0   12   16    0    0]
 [  25   10   33    0    7    0    0]]
Saved PyTorch Model State epoch is 10   correct = 72.33864207879296

Epoch 12
-------------------------------

batch:100    loss: 0.736300 lr: 0.0009763523075816903

batch:200    loss: 0.740028 lr: 0.0009763523075816903

batch:300    loss: 0.738746 lr: 0.0009763523075816903

batch:400    loss: 0.734093 lr: 0.0009763523075816903

batch:500    loss: 0.732715 lr: 0.0009763523075816903

batch:600    loss: 0.733462 lr: 0.0009763523075816903

batch:700    loss: 0.735206 lr: 0.0009763523075816903

batch:800    loss: 0.735040 lr: 0.0009763523075816903

Test Error: 
 Accuracy: 73.4%, Avg loss: 0.770023 

[[1200   34   19   95   11    0    0]
 [  82  778    9   21   10    0    0]
 [  66   15  358    3   19    0    0]
 [ 219   36    1  156   11    0    0]
 [  79   24   24   61  134    0    0]
 [  10    0    1   17   11    0    0]
 [  21    4   42    2    6    0    0]]
Saved PyTorch Model State epoch is 11   correct = 73.3724504051411

Epoch 13
-------------------------------

batch:100    loss: 0.726062 lr: 0.0009719105943553006

batch:200    loss: 0.702408 lr: 0.0009719105943553006

batch:300    loss: 0.694099 lr: 0.0009719105943553006

batch:400    loss: 0.691594 lr: 0.0009719105943553006

batch:500    loss: 0.696128 lr: 0.0009719105943553006

batch:600    loss: 0.695546 lr: 0.0009719105943553006

batch:700    loss: 0.700176 lr: 0.0009719105943553006

batch:800    loss: 0.702133 lr: 0.0009719105943553006

Test Error: 
 Accuracy: 74.7%, Avg loss: 0.750908 

[[1216   21   33   78   11    0    0]
 [  82  761   20   20   17    0    0]
 [  46   15  390    2    8    0    0]
 [ 219   26    6  153   19    0    0]
 [  77   14   38   38  155    0    0]
 [  13    0    0    9   17    0    0]
 [  17    3   45    1    9    0    0]]
Saved PyTorch Model State epoch is 12   correct = 74.74154791841296

Epoch 14
-------------------------------

batch:100    loss: 0.661276 lr: 0.0009671018502735925

batch:200    loss: 0.665889 lr: 0.0009671018502735925

batch:300    loss: 0.687739 lr: 0.0009671018502735925

batch:400    loss: 0.695177 lr: 0.0009671018502735925

batch:500    loss: 0.693816 lr: 0.0009671018502735925

batch:600    loss: 0.698143 lr: 0.0009671018502735925

batch:700    loss: 0.696762 lr: 0.0009671018502735925

batch:800    loss: 0.694020 lr: 0.0009671018502735925

Test Error: 
 Accuracy: 74.0%, Avg loss: 0.771597 

[[1238   18   28   64   11    0    0]
 [  94  743   24   26   13    0    0]
 [  67    9  367    2   16    0    0]
 [ 240   18    5  139   21    0    0]
 [  86   15   28   31  162    0    0]
 [  12    0    1    8   18    0    0]
 [  22    1   41    1   10    0    0]]
Epoch 15
-------------------------------

batch:100    loss: 0.635548 lr: 0.0009619308209864079

batch:200    loss: 0.635703 lr: 0.0009619308209864079

batch:300    loss: 0.637555 lr: 0.0009619308209864079

batch:400    loss: 0.640285 lr: 0.0009619308209864079

batch:500    loss: 0.652715 lr: 0.0009619308209864079

batch:600    loss: 0.651237 lr: 0.0009619308209864079

batch:700    loss: 0.653575 lr: 0.0009619308209864079

batch:800    loss: 0.656266 lr: 0.0009619308209864079

Test Error: 
 Accuracy: 71.8%, Avg loss: 0.841219 

[[1003   66  158  101   31    0    0]
 [  34  786   36   24   20    0    0]
 [  19   11  415    3   13    0    0]
 [ 167   30   22  172   32    0    0]
 [  58   16   35   21  192    0    0]
 [  10    0    2   10   17    0    0]
 [   7    1   54    2   11    0    0]]
Epoch 16
-------------------------------

batch:100    loss: 0.608936 lr: 0.0009564026096753471

batch:200    loss: 0.623602 lr: 0.0009564026096753471

batch:300    loss: 0.626601 lr: 0.0009564026096753471

batch:400    loss: 0.637428 lr: 0.0009564026096753471

batch:500    loss: 0.629500 lr: 0.0009564026096753471

batch:600    loss: 0.633322 lr: 0.0009564026096753471

batch:700    loss: 0.628942 lr: 0.0009564026096753471

batch:800    loss: 0.627051 lr: 0.0009564026096753471

Test Error: 
 Accuracy: 75.4%, Avg loss: 0.736682 

[[1125   60   54  106   14    0    0]
 [  50  806   12   22   10    0    0]
 [  33   18  393    4   13    0    0]
 [ 172   25    6  200   20    0    0]
 [  68   18   32   31  173    0    0]
 [  12    0    0   10   17    0    0]
 [  12    1   49    1   12    0    0]]
Saved PyTorch Model State epoch is 15   correct = 75.35624476110645

Epoch 17
-------------------------------

batch:100    loss: 0.612200 lr: 0.0009505226720175455

batch:200    loss: 0.603692 lr: 0.0009505226720175455

batch:300    loss: 0.598575 lr: 0.0009505226720175455

batch:400    loss: 0.593713 lr: 0.0009505226720175455

batch:500    loss: 0.591756 lr: 0.0009505226720175455

batch:600    loss: 0.589779 lr: 0.0009505226720175455

batch:700    loss: 0.588645 lr: 0.0009505226720175455

batch:800    loss: 0.583842 lr: 0.0009505226720175455

Test Error: 
 Accuracy: 75.1%, Avg loss: 0.746993 

[[1092   58   20  168   21    0    0]
 [  48  807   13   24    8    0    0]
 [  55   16  364    4   22    0    0]
 [ 150   22    1  239   11    0    0]
 [  58   23   22   34  185    0    0]
 [  13    0    0   14   12    0    0]
 [  13    3   44    2   13    0    0]]
Epoch 18
-------------------------------

batch:100    loss: 0.491156 lr: 0.0009442968108015775

batch:200    loss: 0.521272 lr: 0.0009442968108015775

batch:300    loss: 0.541738 lr: 0.0009442968108015775

batch:400    loss: 0.548113 lr: 0.0009442968108015775

batch:500    loss: 0.547367 lr: 0.0009442968108015775

batch:600    loss: 0.543172 lr: 0.0009442968108015775

batch:700    loss: 0.547610 lr: 0.0009442968108015775

batch:800    loss: 0.552888 lr: 0.0009442968108015775

Test Error: 
 Accuracy: 73.5%, Avg loss: 0.793946 

[[1066   61   40  156   36    0    0]
 [  53  795   20   18   14    0    0]
 [  43   18  380    7   13    0    0]
 [ 150   24    4  215   30    0    0]
 [  66   15   35   32  174    0    0]
 [  12    0    2    9   16    0    0]
 [  13    4   46    3    9    0    0]]
Epoch 19
-------------------------------

batch:100    loss: 0.553972 lr: 0.0009377311702008061

batch:200    loss: 0.531089 lr: 0.0009377311702008061

batch:300    loss: 0.524855 lr: 0.0009377311702008061

batch:400    loss: 0.523040 lr: 0.0009377311702008061

batch:500    loss: 0.548468 lr: 0.0009377311702008061

batch:600    loss: 0.564817 lr: 0.0009377311702008061

batch:700    loss: 0.561691 lr: 0.0009377311702008061

batch:800    loss: 0.558416 lr: 0.0009377311702008061

Test Error: 
 Accuracy: 74.7%, Avg loss: 0.756438 

[[1088   71   47  101   51    0    1]
 [  39  809   17   22   13    0    0]
 [  39   12  379    4   26    0    1]
 [ 166   35    7  183   32    0    0]
 [  52   17   16   23  213    0    1]
 [   8    0    1    9   21    0    0]
 [   8    1   49    2   15    0    0]]
Epoch 20
-------------------------------

batch:100    loss: 0.482746 lr: 0.0009308322297098249

batch:200    loss: 0.490528 lr: 0.0009308322297098249

batch:300    loss: 0.498366 lr: 0.0009308322297098249

batch:400    loss: 0.501362 lr: 0.0009308322297098249

batch:500    loss: 0.507123 lr: 0.0009308322297098249

batch:600    loss: 0.512668 lr: 0.0009308322297098249

batch:700    loss: 0.512088 lr: 0.0009308322297098249

batch:800    loss: 0.509435 lr: 0.0009308322297098249

Test Error: 
 Accuracy: 71.6%, Avg loss: 0.865443 

[[1064   62   29  176   22    0    6]
 [  52  783   21   38    6    0    0]
 [  58   17  352    8   17    0    9]
 [ 159   24    6  216   17    0    1]
 [  67   18   29   59  144    0    5]
 [   7    1    2   19   10    0    0]
 [  15    3   41    4    7    0    5]]
Epoch 21
-------------------------------

batch:100    loss: 0.525201 lr: 0.0009236067977499791

batch:200    loss: 0.498867 lr: 0.0009236067977499791

batch:300    loss: 0.493764 lr: 0.0009236067977499791

batch:400    loss: 0.489723 lr: 0.0009236067977499791

batch:500    loss: 0.483326 lr: 0.0009236067977499791

batch:600    loss: 0.486654 lr: 0.0009236067977499791

batch:700    loss: 0.483230 lr: 0.0009236067977499791

batch:800    loss: 0.482552 lr: 0.0009236067977499791

Test Error: 
 Accuracy: 76.9%, Avg loss: 0.736095 

[[1178   56   16   99   10    0    0]
 [  55  804   14   18    9    0    0]
 [  55   20  373    2   11    0    0]
 [ 180   23    2  208    9    1    0]
 [  65   24   21   28  184    0    0]
 [  11    0    2   10   12    4    0]
 [  19    1   43    3    9    0    0]]
Saved PyTorch Model State epoch is 20   correct = 76.86504610226321

Epoch 22
-------------------------------

batch:100    loss: 0.406181 lr: 0.0009160620049502761

batch:200    loss: 0.393651 lr: 0.0009160620049502761

batch:300    loss: 0.400760 lr: 0.0009160620049502761

batch:400    loss: 0.410869 lr: 0.0009160620049502761

batch:500    loss: 0.415861 lr: 0.0009160620049502761

batch:600    loss: 0.425414 lr: 0.0009160620049502761

batch:700    loss: 0.429331 lr: 0.0009160620049502761

batch:800    loss: 0.431856 lr: 0.0009160620049502761

Test Error: 
 Accuracy: 75.9%, Avg loss: 0.796469 

[[1161   54   50   79   13    2    0]
 [  65  766   35   20   14    0    0]
 [  35   12  396    5   13    0    0]
 [ 172   18    2  217   14    0    0]
 [  64   13   38   33  169    5    0]
 [  12    0    1   13   10    3    0]
 [  10    3   51    3    5    0    3]]
Epoch 23
-------------------------------

batch:100    loss: 0.390335 lr: 0.0009082052971103159

batch:200    loss: 0.396430 lr: 0.0009082052971103159

batch:300    loss: 0.405475 lr: 0.0009082052971103159

batch:400    loss: 0.421160 lr: 0.0009082052971103159

batch:500    loss: 0.421045 lr: 0.0009082052971103159

batch:600    loss: 0.421933 lr: 0.0009082052971103159

batch:700    loss: 0.420750 lr: 0.0009082052971103159

batch:800    loss: 0.419912 lr: 0.0009082052971103159

Test Error: 
 Accuracy: 76.2%, Avg loss: 0.800157 

[[1148   50   55   72   34    0    0]
 [  63  772   28   18   19    0    0]
 [  32    8  398    2   21    0    0]
 [ 176   16    8  192   30    1    0]
 [  55    9   25   17  215    1    0]
 [  13    0    0    7   16    3    0]
 [  10    1   51    3   10    0    0]]
Epoch 24
-------------------------------

batch:100    loss: 0.341707 lr: 0.000900044427852184

batch:200    loss: 0.351481 lr: 0.000900044427852184

batch:300    loss: 0.356112 lr: 0.000900044427852184

batch:400    loss: 0.362274 lr: 0.000900044427852184

batch:500    loss: 0.368319 lr: 0.000900044427852184

batch:600    loss: 0.363348 lr: 0.000900044427852184

batch:700    loss: 0.364869 lr: 0.000900044427852184

batch:800    loss: 0.365026 lr: 0.000900044427852184

Test Error: 
 Accuracy: 76.8%, Avg loss: 0.826334 

[[1174   38   30   96   20    0    1]
 [  72  770   13   26   19    0    0]
 [  43   17  374    7   16    0    4]
 [ 175   13    1  213   20    0    1]
 [  60   10   25   25  202    0    0]
 [  12    0    0    7   17    3    0]
 [  14    3   33    4    8    0   13]]
Epoch 25
-------------------------------

batch:100    loss: 0.345197 lr: 0.0008915874509685647

batch:200    loss: 0.351351 lr: 0.0008915874509685647

batch:300    loss: 0.359997 lr: 0.0008915874509685647

batch:400    loss: 0.367062 lr: 0.0008915874509685647

batch:500    loss: 0.365569 lr: 0.0008915874509685647

batch:600    loss: 0.359001 lr: 0.0008915874509685647

batch:700    loss: 0.356314 lr: 0.0008915874509685647

batch:800    loss: 0.353655 lr: 0.0008915874509685647

Test Error: 
 Accuracy: 76.4%, Avg loss: 0.832786 

[[1214   43   25   64   13    0    0]
 [  93  755   15   23   14    0    0]
 [  54   16  363    4   14    0   10]
 [ 195   21    2  193   10    1    1]
 [  80   11   20   25  184    1    1]
 [  15    0    0    8   12    4    0]
 [  14    5   27    2    6    0   21]]
Epoch 26
-------------------------------

batch:100    loss: 0.278048 lr: 0.000882842712474619

batch:200    loss: 0.286229 lr: 0.000882842712474619

batch:300    loss: 0.292477 lr: 0.000882842712474619

batch:400    loss: 0.293268 lr: 0.000882842712474619

batch:500    loss: 0.295842 lr: 0.000882842712474619

batch:600    loss: 0.300216 lr: 0.000882842712474619

batch:700    loss: 0.306135 lr: 0.000882842712474619

batch:800    loss: 0.301997 lr: 0.000882842712474619

Test Error: 
 Accuracy: 74.9%, Avg loss: 0.908215 

[[1071  121   24  123   14    0    6]
 [  37  829    9   16    9    0    0]
 [  39   36  353    6   12    0   15]
 [ 131   42    2  240    6    0    2]
 [  55   39   22   42  163    0    1]
 [  10    0    1   19    7    2    0]
 [  10   11   23    6    4    0   21]]
Epoch 27
-------------------------------

batch:100    loss: 0.245699 lr: 0.0008738188423714755

batch:200    loss: 0.249761 lr: 0.0008738188423714755

batch:300    loss: 0.267666 lr: 0.0008738188423714755

batch:400    loss: 0.289887 lr: 0.0008738188423714755

batch:500    loss: 0.300060 lr: 0.0008738188423714755

batch:600    loss: 0.304215 lr: 0.0008738188423714755

batch:700    loss: 0.303962 lr: 0.0008738188423714755

batch:800    loss: 0.309678 lr: 0.0008738188423714755

Test Error: 
 Accuracy: 75.0%, Avg loss: 0.908059 

[[1174   42   39   66   30    0    8]
 [  78  747   23   25   20    0    7]
 [  45   19  372    6   10    0    9]
 [ 182   14    2  189   27    6    3]
 [  74   11   22   25  181    1    8]
 [  12    0    0    4   19    3    1]
 [  19    1   28    3    4    0   20]]
Epoch 28
-------------------------------

batch:100    loss: 0.266332 lr: 0.0008645247461294607

batch:200    loss: 0.287709 lr: 0.0008645247461294607

batch:300    loss: 0.292663 lr: 0.0008645247461294607

batch:400    loss: 0.296786 lr: 0.0008645247461294607

batch:500    loss: 0.298352 lr: 0.0008645247461294607

batch:600    loss: 0.294475 lr: 0.0008645247461294607

batch:700    loss: 0.298267 lr: 0.0008645247461294607

batch:800    loss: 0.297299 lr: 0.0008645247461294607

Test Error: 
 Accuracy: 76.3%, Avg loss: 0.898793 

[[1143   42   32   98   31    0   13]
 [  63  759   16   24   34    0    4]
 [  36   10  364   10   21    0   20]
 [ 153   20    4  222   20    0    4]
 [  59   11   13   25  212    0    2]
 [  12    0    0    4   16    6    1]
 [   5    4   30    6    6    0   24]]
Epoch 29
-------------------------------

batch:100    loss: 0.280414 lr: 0.0008549695958994758

batch:200    loss: 0.275112 lr: 0.0008549695958994758

batch:300    loss: 0.265498 lr: 0.0008549695958994758

batch:400    loss: 0.283215 lr: 0.0008549695958994758

batch:500    loss: 0.286041 lr: 0.0008549695958994758

batch:600    loss: 0.283934 lr: 0.0008549695958994758

batch:700    loss: 0.284919 lr: 0.0008549695958994758

batch:800    loss: 0.279804 lr: 0.0008549695958994758

Test Error: 
 Accuracy: 76.7%, Avg loss: 0.891551 

[[1150   63   21   90   32    0    3]
 [  66  797   12   11   11    0    3]
 [  57   19  339    4   23    0   19]
 [ 151   28    0  213   29    2    0]
 [  52   20   18   21  208    1    2]
 [   9    0    0    7   15    8    0]
 [  16    4   16    2    8    0   29]]
Epoch 30
-------------------------------

batch:100    loss: 0.214506 lr: 0.0008451628214611906

batch:200    loss: 0.221311 lr: 0.0008451628214611906

batch:300    loss: 0.220476 lr: 0.0008451628214611906

batch:400    loss: 0.232357 lr: 0.0008451628214611906

batch:500    loss: 0.233678 lr: 0.0008451628214611906

batch:600    loss: 0.238083 lr: 0.0008451628214611906

batch:700    loss: 0.241144 lr: 0.0008451628214611906

batch:800    loss: 0.242723 lr: 0.0008451628214611906

Test Error: 
 Accuracy: 76.2%, Avg loss: 0.901154 

[[1096   58   27  119   49    0   10]
 [  57  774   18   25   22    1    3]
 [  30   15  366   10   22    0   18]
 [ 130   17    2  235   33    4    2]
 [  42   10   19   26  223    2    0]
 [  12    0    0    5   15    6    1]
 [   8    2   20    4   14    0   27]]
Epoch 31
-------------------------------

batch:100    loss: 0.191467 lr: 0.0008351141009169894

batch:200    loss: 0.192124 lr: 0.0008351141009169894

batch:300    loss: 0.203926 lr: 0.0008351141009169894

batch:400    loss: 0.213916 lr: 0.0008351141009169894

batch:500    loss: 0.214387 lr: 0.0008351141009169894

batch:600    loss: 0.215406 lr: 0.0008351141009169894

batch:700    loss: 0.218662 lr: 0.0008351141009169894

batch:800    loss: 0.217340 lr: 0.0008351141009169894

Test Error: 
 Accuracy: 75.1%, Avg loss: 0.942572 

[[1081   56   33  139   36    2   12]
 [  48  769   18   32   31    0    2]
 [  34   13  366    5   21    0   22]
 [ 131   16    2  236   32    3    3]
 [  56   13   17   24  202    8    2]
 [   7    0    1   11   17    3    0]
 [   8    1   20    4   12    0   30]]
Epoch 32
-------------------------------

batch:100    loss: 0.238658 lr: 0.0008248333511408524

batch:200    loss: 0.217734 lr: 0.0008248333511408524

batch:300    loss: 0.207260 lr: 0.0008248333511408524

batch:400    loss: 0.205640 lr: 0.0008248333511408524

batch:500    loss: 0.204441 lr: 0.0008248333511408524

batch:600    loss: 0.201742 lr: 0.0008248333511408524

batch:700    loss: 0.204162 lr: 0.0008248333511408524

batch:800    loss: 0.204500 lr: 0.0008248333511408524

Test Error: 
 Accuracy: 76.1%, Avg loss: 1.027292 

[[1155   15   31  114   39    0    5]
 [  93  723   15   37   27    1    4]
 [  48   10  367    4   17    0   15]
 [ 149    8    3  231   25    5    2]
 [  53   12   22   20  212    0    3]
 [   8    0    0   11   12    8    0]
 [  12    3   22    4    8    0   26]]
Epoch 33
-------------------------------

batch:100    loss: 0.163235 lr: 0.0008143307179915986

batch:200    loss: 0.171931 lr: 0.0008143307179915986

batch:300    loss: 0.173970 lr: 0.0008143307179915986

batch:400    loss: 0.177323 lr: 0.0008143307179915986

batch:500    loss: 0.177581 lr: 0.0008143307179915986

batch:600    loss: 0.180015 lr: 0.0008143307179915986

batch:700    loss: 0.181672 lr: 0.0008143307179915986

batch:800    loss: 0.180964 lr: 0.0008143307179915986

Test Error: 
 Accuracy: 76.7%, Avg loss: 0.974243 

[[1140   44   38   87   34    2   14]
 [  77  762   19   16   16    2    8]
 [  38   15  367    1   20    0   20]
 [ 150   16    5  221   21    6    4]
 [  47   11   26   20  212    0    6]
 [   9    0    0    7   16    7    0]
 [  14    2   14    2    7    1   35]]
Epoch 34
-------------------------------

batch:100    loss: 0.163161 lr: 0.0008036165663001486

batch:200    loss: 0.161249 lr: 0.0008036165663001486

batch:300    loss: 0.164211 lr: 0.0008036165663001486

batch:400    loss: 0.161776 lr: 0.0008036165663001486

batch:500    loss: 0.160959 lr: 0.0008036165663001486

batch:600    loss: 0.161580 lr: 0.0008036165663001486

batch:700    loss: 0.161539 lr: 0.0008036165663001486

batch:800    loss: 0.161885 lr: 0.0008036165663001486

Test Error: 
 Accuracy: 75.3%, Avg loss: 0.958483 

[[1029   51   49  164   58    1    7]
 [  54  769   12   38   22    0    5]
 [  20   13  383   10   24    0   11]
 [ 105   16    4  261   28    6    3]
 [  40    9   20   32  215    3    3]
 [   6    0    0    9   12   11    1]
 [   8    1   23    5   11    0   27]]
Epoch 35
-------------------------------

batch:100    loss: 0.151205 lr: 0.0007927014696406862

batch:200    loss: 0.174090 lr: 0.0007927014696406862

batch:300    loss: 0.192030 lr: 0.0007927014696406862

batch:400    loss: 0.192526 lr: 0.0007927014696406862

batch:500    loss: 0.189100 lr: 0.0007927014696406862

batch:600    loss: 0.188879 lr: 0.0007927014696406862

batch:700    loss: 0.187031 lr: 0.0007927014696406862

batch:800    loss: 0.183689 lr: 0.0007927014696406862

Test Error: 
 Accuracy: 76.6%, Avg loss: 1.043744 

[[1119   51   26  120   33    1    9]
 [  64  772   14   32   15    0    3]
 [  37   18  355    9   23    0   19]
 [ 132   13    1  248   20    5    4]
 [  47   13   14   31  212    3    2]
 [  11    0    0   14    9    5    0]
 [  10    3   17    6    8    0   31]]
Epoch 36
-------------------------------

batch:100    loss: 0.138080 lr: 0.0007815961998958187

batch:200    loss: 0.140058 lr: 0.0007815961998958187

batch:300    loss: 0.146929 lr: 0.0007815961998958187

batch:400    loss: 0.141740 lr: 0.0007815961998958187

batch:500    loss: 0.153834 lr: 0.0007815961998958187

batch:600    loss: 0.157015 lr: 0.0007815961998958187

batch:700    loss: 0.159815 lr: 0.0007815961998958187

batch:800    loss: 0.161861 lr: 0.0007815961998958187

Test Error: 
 Accuracy: 76.0%, Avg loss: 0.891906 

[[1131   50   39  108   25    0    6]
 [  74  766   12   28   12    0    8]
 [  46   11  365    6   15    0   18]
 [ 133   26    3  235   16    2    8]
 [  61   19   20   30  184    2    6]
 [  11    0    0   13    8    6    1]
 [  10    2   23    3    5    0   32]]
Epoch 37
-------------------------------

batch:100    loss: 0.191799 lr: 0.0007703117166260292

batch:200    loss: 0.169210 lr: 0.0007703117166260292

batch:300    loss: 0.162644 lr: 0.0007703117166260292

batch:400    loss: 0.167769 lr: 0.0007703117166260292

batch:500    loss: 0.169811 lr: 0.0007703117166260292

batch:600    loss: 0.165950 lr: 0.0007703117166260292

batch:700    loss: 0.165754 lr: 0.0007703117166260292

batch:800    loss: 0.162304 lr: 0.0007703117166260292

Test Error: 
 Accuracy: 76.7%, Avg loss: 1.092819 

[[1164   39   39   88   27    1    1]
 [  83  750   19   17   26    0    5]
 [  38   14  375    3   14    0   17]
 [ 159   16    4  211   24    3    6]
 [  62    9   28   15  203    4    1]
 [   9    0    0   10    9   10    1]
 [   9    2   22    4    6    0   32]]
Epoch 38
-------------------------------

batch:100    loss: 0.098365 lr: 0.0007588591562539122

batch:200    loss: 0.096935 lr: 0.0007588591562539122

batch:300    loss: 0.104368 lr: 0.0007588591562539122

batch:400    loss: 0.107817 lr: 0.0007588591562539122

batch:500    loss: 0.107085 lr: 0.0007588591562539122

batch:600    loss: 0.109396 lr: 0.0007588591562539122

batch:700    loss: 0.109591 lr: 0.0007588591562539122

batch:800    loss: 0.111525 lr: 0.0007588591562539122

Test Error: 
 Accuracy: 75.7%, Avg loss: 1.174475 

[[1097   57   20  141   33    1   10]
 [  73  767   16   25   11    0    8]
 [  48   12  360    7   12    0   22]
 [ 139   16    2  239   13    9    5]
 [  47   13   16   29  197    7   13]
 [   7    0    0   10    8   12    2]
 [  11    2   17    4    4    0   37]]
Epoch 39
-------------------------------

batch:100    loss: 0.104408 lr: 0.0007472498210738714

batch:200    loss: 0.103758 lr: 0.0007472498210738714

batch:300    loss: 0.105260 lr: 0.0007472498210738714

batch:400    loss: 0.112431 lr: 0.0007472498210738714

batch:500    loss: 0.120627 lr: 0.0007472498210738714

batch:600    loss: 0.118522 lr: 0.0007472498210738714

batch:700    loss: 0.121063 lr: 0.0007472498210738714

batch:800    loss: 0.123723 lr: 0.0007472498210738714

Test Error: 
 Accuracy: 77.1%, Avg loss: 1.068997 

[[1141   53   19   96   48    0    2]
 [  68  793    7   14   16    0    2]
 [  51   21  357    5   15    0   12]
 [ 152   28    2  210   22    4    5]
 [  52   20   11   20  215    0    4]
 [   9    0    0    9   12    8    1]
 [   8    5   20    3    5    0   34]]
Saved PyTorch Model State epoch is 38   correct = 77.06063146130204

Epoch 40
-------------------------------

batch:100    loss: 0.092942 lr: 0.0007354951680981168

batch:200    loss: 0.101465 lr: 0.0007354951680981168

batch:300    loss: 0.110810 lr: 0.0007354951680981168

batch:400    loss: 0.108320 lr: 0.0007354951680981168

batch:500    loss: 0.108185 lr: 0.0007354951680981168

batch:600    loss: 0.108907 lr: 0.0007354951680981168

batch:700    loss: 0.111254 lr: 0.0007354951680981168

batch:800    loss: 0.112282 lr: 0.0007354951680981168

Test Error: 
 Accuracy: 76.2%, Avg loss: 1.151222 

[[1087   69   34  123   38    0    8]
 [  52  789   10   31   14    0    4]
 [  37   17  362    7   13    1   24]
 [ 138   15    3  242   21    2    2]
 [  54   19   20   23  199    1    6]
 [  11    0    1   10    6   10    1]
 [   9    3   16    4    5    0   38]]
Epoch 41
-------------------------------

batch:100    loss: 0.108937 lr: 0.0007236067977499789

batch:200    loss: 0.100360 lr: 0.0007236067977499789

batch:300    loss: 0.099608 lr: 0.0007236067977499789

batch:400    loss: 0.105413 lr: 0.0007236067977499789

batch:500    loss: 0.108005 lr: 0.0007236067977499789

batch:600    loss: 0.110333 lr: 0.0007236067977499789

batch:700    loss: 0.109548 lr: 0.0007236067977499789

batch:800    loss: 0.110016 lr: 0.0007236067977499789

Test Error: 
 Accuracy: 76.0%, Avg loss: 1.187869 

[[1096   74   16  137   29    4    3]
 [  51  780    9   38   19    0    3]
 [  54   20  336   10   24    0   17]
 [ 120   18    0  268   11    3    3]
 [  52   16   11   35  197    6    5]
 [   8    0    0   14    8    8    1]
 [  15    3   10    5    7    0   35]]
Epoch 42
-------------------------------

batch:100    loss: 0.113667 lr: 0.0007115964424156918

batch:200    loss: 0.113440 lr: 0.0007115964424156918

batch:300    loss: 0.107897 lr: 0.0007115964424156918

batch:400    loss: 0.102845 lr: 0.0007115964424156918

batch:500    loss: 0.100843 lr: 0.0007115964424156918

batch:600    loss: 0.104240 lr: 0.0007115964424156918

batch:700    loss: 0.101360 lr: 0.0007115964424156918

batch:800    loss: 0.105081 lr: 0.0007115964424156918

Test Error: 
 Accuracy: 76.4%, Avg loss: 1.071260 

[[1160   40   36   88   29    1    5]
 [  87  741   26   25   18    0    3]
 [  38   12  378    6   12    0   15]
 [ 158   17    1  212   22    5    8]
 [  53    7   36   19  196    1   10]
 [   8    0    0   10    7   12    2]
 [  12    1   18    3    4    0   37]]
Epoch 43
-------------------------------

batch:100    loss: 0.089456 lr: 0.0006994759548659419

batch:200    loss: 0.087556 lr: 0.0006994759548659419

batch:300    loss: 0.088648 lr: 0.0006994759548659419

batch:400    loss: 0.092101 lr: 0.0006994759548659419

batch:500    loss: 0.089782 lr: 0.0006994759548659419

batch:600    loss: 0.091301 lr: 0.0006994759548659419

batch:700    loss: 0.101730 lr: 0.0006994759548659419

batch:800    loss: 0.107887 lr: 0.0006994759548659419

Test Error: 
 Accuracy: 76.5%, Avg loss: 1.170350 

[[1142   42   23  117   29    1    5]
 [  74  755   17   25   18    1   10]
 [  42   14  361    9   16    0   19]
 [ 139   16    1  237   12    8   10]
 [  60   13   13   31  193    6    6]
 [   9    0    0   11    8   10    1]
 [  10    1   16    3    5    1   39]]
Epoch 44
-------------------------------

batch:100    loss: 0.080669 lr: 0.0006872572965586171

batch:200    loss: 0.074592 lr: 0.0006872572965586171

batch:300    loss: 0.076536 lr: 0.0006872572965586171

batch:400    loss: 0.080249 lr: 0.0006872572965586171

batch:500    loss: 0.078656 lr: 0.0006872572965586171

batch:600    loss: 0.078692 lr: 0.0006872572965586171

batch:700    loss: 0.079004 lr: 0.0006872572965586171

batch:800    loss: 0.079000 lr: 0.0006872572965586171

Test Error: 
 Accuracy: 74.6%, Avg loss: 1.283626 

[[1105   71   42   54   44    5   38]
 [  57  781   19   10   15    2   16]
 [  21   18  374    2   16    0   30]
 [ 171   30    6  165   20   11   20]
 [  46   24   24   17  197    4   10]
 [  12    0    0    6    8   12    1]
 [   4    2   25    4    5    0   35]]
Epoch 45
-------------------------------

batch:100    loss: 0.102947 lr: 0.0006749525258342899

batch:200    loss: 0.083383 lr: 0.0006749525258342899

batch:300    loss: 0.078617 lr: 0.0006749525258342899

batch:400    loss: 0.075900 lr: 0.0006749525258342899

batch:500    loss: 0.075426 lr: 0.0006749525258342899

batch:600    loss: 0.078394 lr: 0.0006749525258342899

batch:700    loss: 0.086792 lr: 0.0006749525258342899

batch:800    loss: 0.089792 lr: 0.0006749525258342899

Test Error: 
 Accuracy: 75.7%, Avg loss: 1.231790 

[[1072   54   33  158   36    0    6]
 [  67  779   24   18    9    1    2]
 [  36   18  380    4    9    0   14]
 [ 123   16    5  256   13    3    7]
 [  47   21   33   24  179    8   10]
 [   7    0    0   14    7   11    0]
 [   7    4   21    6    5    0   32]]
Epoch 46
-------------------------------

batch:100    loss: 0.078629 lr: 0.0006625737860160925

batch:200    loss: 0.085064 lr: 0.0006625737860160925

batch:300    loss: 0.080063 lr: 0.0006625737860160925

batch:400    loss: 0.077107 lr: 0.0006625737860160925

batch:500    loss: 0.073841 lr: 0.0006625737860160925

batch:600    loss: 0.079242 lr: 0.0006625737860160925

batch:700    loss: 0.089636 lr: 0.0006625737860160925

batch:800    loss: 0.092755 lr: 0.0006625737860160925

Test Error: 
 Accuracy: 76.6%, Avg loss: 1.173603 

[[1103   56   28  116   47    0    9]
 [  63  778   23   22    9    2    3]
 [  41   13  366    9   12    0   20]
 [ 129   19    2  252   13    3    5]
 [  42   20   24   26  197    2   11]
 [   6    0    0   10    9   12    2]
 [  11    4   16    6    4    0   34]]
Epoch 47
-------------------------------

batch:100    loss: 0.082578 lr: 0.0006501332934257218

batch:200    loss: 0.074460 lr: 0.0006501332934257218

batch:300    loss: 0.070862 lr: 0.0006501332934257218

batch:400    loss: 0.076465 lr: 0.0006501332934257218

batch:500    loss: 0.075277 lr: 0.0006501332934257218

batch:600    loss: 0.076527 lr: 0.0006501332934257218

batch:700    loss: 0.075763 lr: 0.0006501332934257218

batch:800    loss: 0.074940 lr: 0.0006501332934257218

Test Error: 
 Accuracy: 76.8%, Avg loss: 1.311282 

[[1137   41   24  118   28    1   10]
 [  77  772   14   18   15    1    3]
 [  45   17  354    6   18    0   21]
 [ 143   15    3  241   13    4    4]
 [  58   12   24   20  196    4    8]
 [  13    0    0    6    7   12    1]
 [  10    3   16    3    7    0   36]]
Epoch 48
-------------------------------

batch:100    loss: 0.076447 lr: 0.0006376433253274058

batch:200    loss: 0.069276 lr: 0.0006376433253274058

batch:300    loss: 0.078080 lr: 0.0006376433253274058

batch:400    loss: 0.074436 lr: 0.0006376433253274058

batch:500    loss: 0.073231 lr: 0.0006376433253274058

batch:600    loss: 0.076884 lr: 0.0006376433253274058

batch:700    loss: 0.074004 lr: 0.0006376433253274058

batch:800    loss: 0.072776 lr: 0.0006376433253274058

Test Error: 
 Accuracy: 75.5%, Avg loss: 1.258849 

[[1086   58   21  135   38    0   21]
 [  64  780   11   23   13    0    9]
 [  28   17  337    4   31    0   44]
 [ 131   18    1  246   20    1    6]
 [  56   16    9   29  200    2   10]
 [   8    0    0   12    8   11    0]
 [   5    3   13    7    6    0   41]]
Epoch 49
-------------------------------

batch:100    loss: 0.066492 lr: 0.0006251162078117254

batch:200    loss: 0.062238 lr: 0.0006251162078117254

batch:300    loss: 0.061383 lr: 0.0006251162078117254

batch:400    loss: 0.061045 lr: 0.0006251162078117254

batch:500    loss: 0.059888 lr: 0.0006251162078117254

batch:600    loss: 0.062432 lr: 0.0006251162078117254

batch:700    loss: 0.062986 lr: 0.0006251162078117254

batch:800    loss: 0.065933 lr: 0.0006251162078117254

Test Error: 
 Accuracy: 76.1%, Avg loss: 1.118210 

[[1130   56   28  112   25    0    8]
 [  73  766   17   24   14    0    6]
 [  46   16  350    8   18    0   23]
 [ 144   18    2  235   16    4    4]
 [  56   15   17   28  193    4    9]
 [   5    0    0   15    9   10    0]
 [  10    4   15    3    5    0   38]]
Epoch 50
-------------------------------

batch:100    loss: 0.091328 lr: 0.0006125643036312513

batch:200    loss: 0.086638 lr: 0.0006125643036312513

batch:300    loss: 0.081825 lr: 0.0006125643036312513

batch:400    loss: 0.075807 lr: 0.0006125643036312513

batch:500    loss: 0.073082 lr: 0.0006125643036312513

batch:600    loss: 0.070575 lr: 0.0006125643036312513

batch:700    loss: 0.067379 lr: 0.0006125643036312513

batch:800    loss: 0.067251 lr: 0.0006125643036312513

Test Error: 
 Accuracy: 76.9%, Avg loss: 1.287244 

[[1179   41   23   93   19    1    3]
 [  83  756   21   22   12    1    5]
 [  51   17  357    5   15    0   16]
 [ 168   10    3  228    9    3    2]
 [  72   13   19   23  184    2    9]
 [  10    0    0    7    9   11    2]
 [  14    4   13    2    3    0   39]]
Epoch 51
-------------------------------

batch:100    loss: 0.069762 lr: 0.0006000000000000001

batch:200    loss: 0.070686 lr: 0.0006000000000000001

batch:300    loss: 0.069236 lr: 0.0006000000000000001

batch:400    loss: 0.067857 lr: 0.0006000000000000001

batch:500    loss: 0.067745 lr: 0.0006000000000000001

batch:600    loss: 0.066255 lr: 0.0006000000000000001

batch:700    loss: 0.064767 lr: 0.0006000000000000001

batch:800    loss: 0.062849 lr: 0.0006000000000000001

Test Error: 
 Accuracy: 76.5%, Avg loss: 1.374430 

[[1154   47   19  113   14    1   11]
 [  73  764   14   21   11    2   15]
 [  49   13  347    6   18    0   28]
 [ 148   16    1  225   17   10    6]
 [  59   16   15   27  195    5    5]
 [  10    0    0    6    9   13    1]
 [  10    2   14    4    5    0   40]]
Epoch 52
-------------------------------

batch:100    loss: 0.066281 lr: 0.0005874356963687487

batch:200    loss: 0.071807 lr: 0.0005874356963687487

batch:300    loss: 0.068392 lr: 0.0005874356963687487

batch:400    loss: 0.063576 lr: 0.0005874356963687487

batch:500    loss: 0.060999 lr: 0.0005874356963687487

batch:600    loss: 0.058104 lr: 0.0005874356963687487

batch:700    loss: 0.055972 lr: 0.0005874356963687487

batch:800    loss: 0.055518 lr: 0.0005874356963687487

Test Error: 
 Accuracy: 77.1%, Avg loss: 1.296871 

[[1133   60   29  100   28    0    9]
 [  67  779   18   17   13    0    6]
 [  48   10  363    4   15    0   21]
 [ 148   16    1  229   16    7    6]
 [  54   14   24   22  201    4    3]
 [   6    0    0   11    8   13    1]
 [   8    4   15    3    5    0   40]]
Epoch 53
-------------------------------

batch:100    loss: 0.041505 lr: 0.0005748837921882747

batch:200    loss: 0.038309 lr: 0.0005748837921882747

batch:300    loss: 0.039979 lr: 0.0005748837921882747

batch:400    loss: 0.042123 lr: 0.0005748837921882747

batch:500    loss: 0.048405 lr: 0.0005748837921882747

batch:600    loss: 0.050735 lr: 0.0005748837921882747

batch:700    loss: 0.052475 lr: 0.0005748837921882747

batch:800    loss: 0.054135 lr: 0.0005748837921882747

Test Error: 
 Accuracy: 77.1%, Avg loss: 1.288246 

[[1138   49   31  115   16    0   10]
 [  77  774   15   18    8    0    8]
 [  35   13  374    7   13    0   19]
 [ 157   13    2  229   13    4    5]
 [  63   11   20   21  194    3   10]
 [  10    0    0   10    8   10    1]
 [  10    4   15    2    2    0   42]]
Saved PyTorch Model State epoch is 52   correct = 77.14445375803297

Epoch 54
-------------------------------

batch:100    loss: 0.040695 lr: 0.0005623566746725943

batch:200    loss: 0.047746 lr: 0.0005623566746725943

batch:300    loss: 0.046249 lr: 0.0005623566746725943

batch:400    loss: 0.045424 lr: 0.0005623566746725943

batch:500    loss: 0.046922 lr: 0.0005623566746725943

batch:600    loss: 0.055856 lr: 0.0005623566746725943

batch:700    loss: 0.056870 lr: 0.0005623566746725943

batch:800    loss: 0.056314 lr: 0.0005623566746725943

Test Error: 
 Accuracy: 76.4%, Avg loss: 1.357643 

[[1080   67   27  144   31    3    7]
 [  54  798   15   18    9    1    5]
 [  29   16  365    5   24    0   22]
 [ 128   29    2  237   13    8    6]
 [  46   18   17   31  200    6    4]
 [   6    0    0   10    7   16    0]
 [  10    4   17    3    3    1   37]]
Epoch 55
-------------------------------

batch:100    loss: 0.039681 lr: 0.0005498667065742783

batch:200    loss: 0.042293 lr: 0.0005498667065742783

batch:300    loss: 0.039662 lr: 0.0005498667065742783

batch:400    loss: 0.039617 lr: 0.0005498667065742783

batch:500    loss: 0.037838 lr: 0.0005498667065742783

batch:600    loss: 0.038903 lr: 0.0005498667065742783

batch:700    loss: 0.040570 lr: 0.0005498667065742783

batch:800    loss: 0.043627 lr: 0.0005498667065742783

Test Error: 
 Accuracy: 77.5%, Avg loss: 1.262915 

[[1167   58   25   75   27    0    7]
 [  59  790   14   14   15    1    7]
 [  45   16  361    4   17    0   18]
 [ 176   20    3  201   12    5    6]
 [  55   14   21   20  204    2    6]
 [   9    0    0    9    7   12    2]
 [  10    4   15    2    5    0   39]]
Saved PyTorch Model State epoch is 54   correct = 77.50768371053367

Epoch 56
-------------------------------

batch:100    loss: 0.036058 lr: 0.0005374262139839077

batch:200    loss: 0.038262 lr: 0.0005374262139839077

batch:300    loss: 0.035483 lr: 0.0005374262139839077

batch:400    loss: 0.037593 lr: 0.0005374262139839077

batch:500    loss: 0.037535 lr: 0.0005374262139839077

batch:600    loss: 0.038490 lr: 0.0005374262139839077

batch:700    loss: 0.038732 lr: 0.0005374262139839077

batch:800    loss: 0.038008 lr: 0.0005374262139839077

Test Error: 
 Accuracy: 76.8%, Avg loss: 1.422442 

[[1181   35   25   81   29    0    8]
 [  91  741   24   19   15    0   10]
 [  46    8  364    8   20    0   15]
 [ 166   11    2  217   15    7    5]
 [  65    9   25   18  195    5    5]
 [  15    0    0    2    7   14    1]
 [  12    3   15    2    5    0   38]]
Epoch 57
-------------------------------

batch:100    loss: 0.041762 lr: 0.0005250474741657102

batch:200    loss: 0.042566 lr: 0.0005250474741657102

batch:300    loss: 0.041232 lr: 0.0005250474741657102

batch:400    loss: 0.041860 lr: 0.0005250474741657102

batch:500    loss: 0.042842 lr: 0.0005250474741657102

batch:600    loss: 0.042436 lr: 0.0005250474741657102

batch:700    loss: 0.042444 lr: 0.0005250474741657102

batch:800    loss: 0.042899 lr: 0.0005250474741657102

Test Error: 
 Accuracy: 77.6%, Avg loss: 1.360256 

[[1133   55   24   93   36    1   17]
 [  59  792   10   15   19    0    5]
 [  37   13  365    8   17    0   21]
 [ 147   18    1  231   16    3    7]
 [  59   20   18   16  201    2    6]
 [  10    0    0    7    9   12    1]
 [   7    3   12    4    4    0   45]]
Saved PyTorch Model State epoch is 56   correct = 77.64738753841856

Epoch 58
-------------------------------

batch:100    loss: 0.030237 lr: 0.0005127427034413832

batch:200    loss: 0.034061 lr: 0.0005127427034413832

batch:300    loss: 0.044880 lr: 0.0005127427034413832

batch:400    loss: 0.045987 lr: 0.0005127427034413832

batch:500    loss: 0.049282 lr: 0.0005127427034413832

batch:600    loss: 0.051554 lr: 0.0005127427034413832

batch:700    loss: 0.049554 lr: 0.0005127427034413832

batch:800    loss: 0.048956 lr: 0.0005127427034413832

Test Error: 
 Accuracy: 76.4%, Avg loss: 1.309302 

[[1089   65   12  145   29    1   18]
 [  66  780    6   29   12    0    7]
 [  44   14  345    6   26    0   26]
 [ 120   21    0  259   10    5    8]
 [  52   16   14   27  201    6    6]
 [   9    0    0    9    8   13    0]
 [   9    4    9    4    3    0   46]]
Epoch 59
-------------------------------

batch:100    loss: 0.030812 lr: 0.0005005240451340581

batch:200    loss: 0.030885 lr: 0.0005005240451340581

batch:300    loss: 0.030160 lr: 0.0005005240451340581

batch:400    loss: 0.034825 lr: 0.0005005240451340581

batch:500    loss: 0.035173 lr: 0.0005005240451340581

batch:600    loss: 0.035405 lr: 0.0005005240451340581

batch:700    loss: 0.036096 lr: 0.0005005240451340581

batch:800    loss: 0.035903 lr: 0.0005005240451340581

Test Error: 
 Accuracy: 77.4%, Avg loss: 1.354322 

[[1167   56   21   81   22    0   12]
 [  66  779   11   23   13    1    7]
 [  45   13  349    9   21    0   24]
 [ 156   19    1  223   12    6    6]
 [  58   17   14   29  193    5    6]
 [  11    0    0    8    7   13    0]
 [  10    4   10    3    3    0   45]]
Epoch 60
-------------------------------

batch:100    loss: 0.040904 lr: 0.0004884035575843084

batch:200    loss: 0.037441 lr: 0.0004884035575843084

batch:300    loss: 0.033701 lr: 0.0004884035575843084

batch:400    loss: 0.030408 lr: 0.0004884035575843084

batch:500    loss: 0.030344 lr: 0.0004884035575843084

batch:600    loss: 0.030156 lr: 0.0004884035575843084

batch:700    loss: 0.029203 lr: 0.0004884035575843084

batch:800    loss: 0.029101 lr: 0.0004884035575843084

Test Error: 
 Accuracy: 76.1%, Avg loss: 1.422795 

[[1140   67   23  109   14    0    6]
 [  63  777   14   24   17    1    4]
 [  48   14  351   10   17    0   21]
 [ 157   20    1  232    8    2    3]
 [  61   16   11   42  182    3    7]
 [  13    0    0   11    7    8    0]
 [  14    3   14    3    7    0   34]]
Epoch 61
-------------------------------

batch:100    loss: 0.037106 lr: 0.0004763932022500212

batch:200    loss: 0.033096 lr: 0.0004763932022500212

batch:300    loss: 0.032776 lr: 0.0004763932022500212

batch:400    loss: 0.033165 lr: 0.0004763932022500212

batch:500    loss: 0.032706 lr: 0.0004763932022500212

batch:600    loss: 0.031426 lr: 0.0004763932022500212

batch:700    loss: 0.031333 lr: 0.0004763932022500212

batch:800    loss: 0.031643 lr: 0.0004763932022500212

Test Error: 
 Accuracy: 76.8%, Avg loss: 1.384537 

[[1131   44   26  116   26    0   16]
 [  68  770   17   23   14    1    7]
 [  34   11  370    6   13    0   27]
 [ 148   11    2  225   19    8   10]
 [  52   11   26   24  198    3    8]
 [  10    0    0    4   12   13    0]
 [   7    4   15    4    3    0   42]]
Epoch 62
-------------------------------

batch:100    loss: 0.030315 lr: 0.00046450483190188345

batch:200    loss: 0.027937 lr: 0.00046450483190188345

batch:300    loss: 0.031006 lr: 0.00046450483190188345

batch:400    loss: 0.033545 lr: 0.00046450483190188345

batch:500    loss: 0.034334 lr: 0.00046450483190188345

batch:600    loss: 0.034237 lr: 0.00046450483190188345

batch:700    loss: 0.034126 lr: 0.00046450483190188345

batch:800    loss: 0.034219 lr: 0.00046450483190188345

Test Error: 
 Accuracy: 77.0%, Avg loss: 1.368485 

[[1106   65   19  140   22    0    7]
 [  56  794    9   26   12    0    3]
 [  45   18  360    8   12    1   17]
 [ 128   22    1  253    7    6    6]
 [  53   23   15   24  195    7    5]
 [  10    0    0   12    5   12    0]
 [  11    7   14    5    3    0   35]]
Epoch 63
-------------------------------

batch:100    loss: 0.022140 lr: 0.000452750178926129

batch:200    loss: 0.023914 lr: 0.000452750178926129

batch:300    loss: 0.025557 lr: 0.000452750178926129

batch:400    loss: 0.028339 lr: 0.000452750178926129

batch:500    loss: 0.027329 lr: 0.000452750178926129

batch:600    loss: 0.029313 lr: 0.000452750178926129

batch:700    loss: 0.028941 lr: 0.000452750178926129

batch:800    loss: 0.029195 lr: 0.000452750178926129

Test Error: 
 Accuracy: 77.5%, Avg loss: 1.415497 

[[1197   25   19   87   25    2    4]
 [  89  756   14   21   10    2    8]
 [  50   13  352    6   15    0   25]
 [ 170   13    1  213   12    8    6]
 [  57   10   13   24  198   11    9]
 [  11    0    0    6    8   14    0]
 [  12    2   13    2    3    0   43]]
Epoch 64
-------------------------------

batch:100    loss: 0.026721 lr: 0.0004411408437460878

batch:200    loss: 0.030198 lr: 0.0004411408437460878

batch:300    loss: 0.027763 lr: 0.0004411408437460878

batch:400    loss: 0.029256 lr: 0.0004411408437460878

batch:500    loss: 0.029071 lr: 0.0004411408437460878

batch:600    loss: 0.028659 lr: 0.0004411408437460878

batch:700    loss: 0.031429 lr: 0.0004411408437460878

batch:800    loss: 0.031687 lr: 0.0004411408437460878

Test Error: 
 Accuracy: 77.4%, Avg loss: 1.372544 

[[1148   64   20   78   36    2   11]
 [  59  792   12   17    8    1   11]
 [  44   14  359    2   21    0   21]
 [ 156   23    2  210   17    6    9]
 [  56   15   20   16  205    2    8]
 [  11    0    0    6    8   14    0]
 [  10    4   14    3    3    0   41]]
Epoch 65
-------------------------------

batch:100    loss: 0.031102 lr: 0.000429688283373971

batch:200    loss: 0.030607 lr: 0.000429688283373971

batch:300    loss: 0.029652 lr: 0.000429688283373971

batch:400    loss: 0.026387 lr: 0.000429688283373971

batch:500    loss: 0.027889 lr: 0.000429688283373971

batch:600    loss: 0.026998 lr: 0.000429688283373971

batch:700    loss: 0.026725 lr: 0.000429688283373971

batch:800    loss: 0.027193 lr: 0.000429688283373971

Test Error: 
 Accuracy: 77.0%, Avg loss: 1.393208 

[[1135   47   18  120   25    3   11]
 [  73  772    9   25   12    1    8]
 [  48   18  338    7   15    0   35]
 [ 140   13    1  246    5    8   10]
 [  50   13   14   28  204    6    7]
 [  10    0    0   11    4   12    2]
 [   6    2    8    6    5    0   48]]
Epoch 66
-------------------------------

batch:100    loss: 0.020905 lr: 0.00041840380010418134

batch:200    loss: 0.026318 lr: 0.00041840380010418134

batch:300    loss: 0.028393 lr: 0.00041840380010418134

batch:400    loss: 0.027118 lr: 0.00041840380010418134

batch:500    loss: 0.026596 lr: 0.00041840380010418134

batch:600    loss: 0.025926 lr: 0.00041840380010418134

batch:700    loss: 0.026799 lr: 0.00041840380010418134

batch:800    loss: 0.027700 lr: 0.00041840380010418134

Test Error: 
 Accuracy: 78.2%, Avg loss: 1.418808 

[[1184   58   33   59   21    0    4]
 [  67  784   17   13   12    1    6]
 [  31   18  376    4   17    0   15]
 [ 176   22    2  204    9    4    6]
 [  64   17   26   17  194    3    1]
 [  15    0    0    6    4   12    2]
 [   8    1   17    3    3    0   43]]
Saved PyTorch Model State epoch is 65   correct = 78.15032131880415

Epoch 67
-------------------------------

batch:100    loss: 0.021811 lr: 0.00040729853035931387

batch:200    loss: 0.024992 lr: 0.00040729853035931387

batch:300    loss: 0.024050 lr: 0.00040729853035931387

batch:400    loss: 0.022207 lr: 0.00040729853035931387

batch:500    loss: 0.021104 lr: 0.00040729853035931387

batch:600    loss: 0.022657 lr: 0.00040729853035931387

batch:700    loss: 0.023834 lr: 0.00040729853035931387

batch:800    loss: 0.024814 lr: 0.00040729853035931387

Test Error: 
 Accuracy: 77.5%, Avg loss: 1.368002 

[[1123   65   17  122   24    1    7]
 [  62  790   10   20   11    1    6]
 [  49   19  350    7   18    0   18]
 [ 125   23    0  255   12    4    4]
 [  51   17   23   24  201    4    2]
 [  10    0    0   10    6   12    1]
 [   9    3   13    5    4    0   41]]
Epoch 68
-------------------------------

batch:100    loss: 0.023246 lr: 0.0003963834336998515

batch:200    loss: 0.023046 lr: 0.0003963834336998515

batch:300    loss: 0.021349 lr: 0.0003963834336998515

batch:400    loss: 0.022495 lr: 0.0003963834336998515

batch:500    loss: 0.021215 lr: 0.0003963834336998515

batch:600    loss: 0.021112 lr: 0.0003963834336998515

batch:700    loss: 0.021246 lr: 0.0003963834336998515

batch:800    loss: 0.021559 lr: 0.0003963834336998515

Test Error: 
 Accuracy: 77.7%, Avg loss: 1.474841 

[[1147   54   29   79   34    0   16]
 [  66  777   17   17   14    1    8]
 [  34   16  373    3   19    0   16]
 [ 165   21    1  209   16    6    5]
 [  49   13   20   16  217    4    3]
 [  11    0    0    4    8   15    1]
 [  10    3   14    2    4    0   42]]
Epoch 69
-------------------------------

batch:100    loss: 0.021619 lr: 0.0003856692820084013

batch:200    loss: 0.019081 lr: 0.0003856692820084013

batch:300    loss: 0.019412 lr: 0.0003856692820084013

batch:400    loss: 0.017257 lr: 0.0003856692820084013

batch:500    loss: 0.017345 lr: 0.0003856692820084013

batch:600    loss: 0.019443 lr: 0.0003856692820084013

batch:700    loss: 0.021653 lr: 0.0003856692820084013

batch:800    loss: 0.021992 lr: 0.0003856692820084013

Test Error: 
 Accuracy: 77.4%, Avg loss: 1.456805 

[[1125   57   17  115   31    2   12]
 [  62  786   11   23    9    1    8]
 [  47   17  346    5   23    0   23]
 [ 128   14    2  255   11    4    9]
 [  48   18   13   26  204    7    6]
 [   6    1    0    9    9   12    2]
 [   7    3   11    5    7    0   42]]
Epoch 70
-------------------------------

batch:100    loss: 0.027623 lr: 0.00037516664885914775

batch:200    loss: 0.023189 lr: 0.00037516664885914775

batch:300    loss: 0.022708 lr: 0.00037516664885914775

batch:400    loss: 0.024408 lr: 0.00037516664885914775

batch:500    loss: 0.023215 lr: 0.00037516664885914775

batch:600    loss: 0.022021 lr: 0.00037516664885914775

batch:700    loss: 0.022921 lr: 0.00037516664885914775

batch:800    loss: 0.023015 lr: 0.00037516664885914775

Test Error: 
 Accuracy: 78.2%, Avg loss: 1.471884 

[[1189   43   22   85   15    0    5]
 [  79  780   10   17   12    0    2]
 [  53   18  360    4   15    0   11]
 [ 163   16    1  224   10    2    7]
 [  66   15   25   13  194    0    9]
 [  15    1    0    6    7   10    0]
 [  11    2   13    2    4    0   43]]
Saved PyTorch Model State epoch is 69   correct = 78.23414361553506

Epoch 71
-------------------------------

batch:100    loss: 0.026591 lr: 0.00036488589908301085

batch:200    loss: 0.024055 lr: 0.00036488589908301085

batch:300    loss: 0.020599 lr: 0.00036488589908301085

batch:400    loss: 0.018321 lr: 0.00036488589908301085

batch:500    loss: 0.017964 lr: 0.00036488589908301085

batch:600    loss: 0.019008 lr: 0.00036488589908301085

batch:700    loss: 0.019740 lr: 0.00036488589908301085

batch:800    loss: 0.020157 lr: 0.00036488589908301085

Test Error: 
 Accuracy: 77.4%, Avg loss: 1.507395 

[[1159   44   19  100   28    1    8]
 [  67  777   11   29   10    1    5]
 [  50   13  351    9   20    0   18]
 [ 148   15    2  234   13    5    6]
 [  52   13   20   29  196    9    3]
 [   9    0    0   11    5   14    0]
 [  12    2   14    3    5    0   39]]
Epoch 72
-------------------------------

batch:100    loss: 0.022608 lr: 0.0003548371785388094

batch:200    loss: 0.023020 lr: 0.0003548371785388094

batch:300    loss: 0.022105 lr: 0.0003548371785388094

batch:400    loss: 0.020269 lr: 0.0003548371785388094

batch:500    loss: 0.020185 lr: 0.0003548371785388094

batch:600    loss: 0.020193 lr: 0.0003548371785388094

batch:700    loss: 0.019780 lr: 0.0003548371785388094

batch:800    loss: 0.020922 lr: 0.0003548371785388094

Test Error: 
 Accuracy: 76.9%, Avg loss: 1.569931 

[[1148   57   33   92   20    0    9]
 [  64  786   14   21   11    1    3]
 [  42   15  360    8   14    1   21]
 [ 151   21    4  217   17    6    7]
 [  49   19   22   25  192    8    7]
 [  12    0    0    8    8   11    0]
 [  12    2   15    3    3    0   40]]
Epoch 73
-------------------------------

batch:100    loss: 0.020123 lr: 0.0003450304041005241

batch:200    loss: 0.019639 lr: 0.0003450304041005241

batch:300    loss: 0.017739 lr: 0.0003450304041005241

batch:400    loss: 0.021598 lr: 0.0003450304041005241

batch:500    loss: 0.023206 lr: 0.0003450304041005241

batch:600    loss: 0.025167 lr: 0.0003450304041005241

batch:700    loss: 0.025811 lr: 0.0003450304041005241

batch:800    loss: 0.025474 lr: 0.0003450304041005241

Test Error: 
 Accuracy: 77.1%, Avg loss: 1.438942 

[[1133   64   23   90   36    1   12]
 [  64  794    9   16   11    1    5]
 [  41   17  357    5   20    0   21]
 [ 148   27    2  212   18    8    8]
 [  51   13   16   21  209    5    7]
 [   9    0    0    7   11   12    0]
 [   9    2   13    3    5    0   43]]
Epoch 74
-------------------------------

batch:100    loss: 0.016471 lr: 0.00033547525387053935

batch:200    loss: 0.018481 lr: 0.00033547525387053935

batch:300    loss: 0.018630 lr: 0.00033547525387053935

batch:400    loss: 0.019303 lr: 0.00033547525387053935

batch:500    loss: 0.019182 lr: 0.00033547525387053935

batch:600    loss: 0.020885 lr: 0.00033547525387053935

batch:700    loss: 0.019911 lr: 0.00033547525387053935

batch:800    loss: 0.019502 lr: 0.00033547525387053935

Test Error: 
 Accuracy: 78.3%, Avg loss: 1.520867 

[[1176   40   46   68   21    0    8]
 [  68  773   23   20   10    0    6]
 [  32   12  386    5   13    0   13]
 [ 157   19    2  210   17    8   10]
 [  47   16   26   20  207    4    2]
 [  12    0    1    4   10   12    0]
 [  10    2   20    3    2    0   38]]
Saved PyTorch Model State epoch is 73   correct = 78.29002514668902

Epoch 75
-------------------------------

batch:100    loss: 0.011461 lr: 0.00032618115762852453

batch:200    loss: 0.016589 lr: 0.00032618115762852453

batch:300    loss: 0.014024 lr: 0.00032618115762852453

batch:400    loss: 0.014013 lr: 0.00032618115762852453

batch:500    loss: 0.013187 lr: 0.00032618115762852453

batch:600    loss: 0.012130 lr: 0.00032618115762852453

batch:700    loss: 0.013900 lr: 0.00032618115762852453

batch:800    loss: 0.014631 lr: 0.00032618115762852453

Test Error: 
 Accuracy: 77.5%, Avg loss: 1.496336 

[[1151   45   22  105   29    0    7]
 [  72  758   11   38   14    0    7]
 [  44   11  355    6   25    0   20]
 [ 142   13    1  245   14    5    3]
 [  55    9   16   25  210    6    1]
 [   8    0    0   10    8   13    0]
 [  12    2   13    3    4    0   41]]
Epoch 76
-------------------------------

batch:100    loss: 0.014982 lr: 0.00031715728752538104

batch:200    loss: 0.012439 lr: 0.00031715728752538104

batch:300    loss: 0.011859 lr: 0.00031715728752538104

batch:400    loss: 0.014376 lr: 0.00031715728752538104

batch:500    loss: 0.014297 lr: 0.00031715728752538104

batch:600    loss: 0.013616 lr: 0.00031715728752538104

batch:700    loss: 0.013350 lr: 0.00031715728752538104

batch:800    loss: 0.014229 lr: 0.00031715728752538104

Test Error: 
 Accuracy: 76.6%, Avg loss: 1.628616 

[[1144   63   34   79   31    1    7]
 [  68  772   13   21   15    1   10]
 [  44   11  362    4   22    1   17]
 [ 165   15    2  209   17   10    5]
 [  50   14   23   20  205    3    7]
 [  12    0    0    6   10   11    0]
 [   8    1   15    6    6    0   39]]
Epoch 77
-------------------------------

batch:100    loss: 0.012893 lr: 0.0003084125490314355

batch:200    loss: 0.013961 lr: 0.0003084125490314355

batch:300    loss: 0.016812 lr: 0.0003084125490314355

batch:400    loss: 0.017304 lr: 0.0003084125490314355

batch:500    loss: 0.017554 lr: 0.0003084125490314355

batch:600    loss: 0.018948 lr: 0.0003084125490314355

batch:700    loss: 0.021632 lr: 0.0003084125490314355

batch:800    loss: 0.021356 lr: 0.0003084125490314355

Test Error: 
 Accuracy: 78.3%, Avg loss: 1.452453 

[[1169   49   27   81   25    0    8]
 [  69  785   11   18   12    0    5]
 [  40   17  365    4   15    0   20]
 [ 153   19    2  222   14    4    9]
 [  48   18   22   20  208    2    4]
 [  13    0    0    7    8   11    0]
 [  10    1   15    3    4    0   42]]
Epoch 78
-------------------------------

batch:100    loss: 0.012897 lr: 0.00029995557214781624

batch:200    loss: 0.017367 lr: 0.00029995557214781624

batch:300    loss: 0.016922 lr: 0.00029995557214781624

batch:400    loss: 0.016006 lr: 0.00029995557214781624

batch:500    loss: 0.015446 lr: 0.00029995557214781624

batch:600    loss: 0.015030 lr: 0.00029995557214781624

batch:700    loss: 0.014865 lr: 0.00029995557214781624

batch:800    loss: 0.016094 lr: 0.00029995557214781624

Test Error: 
 Accuracy: 78.0%, Avg loss: 1.507967 

[[1158   44   30   82   36    2    7]
 [  67  779   12   21   12    0    9]
 [  46   16  361    5   20    0   13]
 [ 147   14    1  228   19   10    4]
 [  48   14   21   19  213    4    3]
 [   7    0    0    8    9   14    1]
 [  13    1   13    4    7    0   37]]
Epoch 79
-------------------------------

batch:100    loss: 0.021960 lr: 0.00029179470288968434

batch:200    loss: 0.017867 lr: 0.00029179470288968434

batch:300    loss: 0.013957 lr: 0.00029179470288968434

batch:400    loss: 0.013642 lr: 0.00029179470288968434

batch:500    loss: 0.012775 lr: 0.00029179470288968434

batch:600    loss: 0.012255 lr: 0.00029179470288968434

batch:700    loss: 0.012843 lr: 0.00029179470288968434

batch:800    loss: 0.012952 lr: 0.00029179470288968434

Test Error: 
 Accuracy: 78.3%, Avg loss: 1.526050 

[[1137   56   27  107   28    0    4]
 [  65  795    7   22    9    0    2]
 [  39   22  370    5   12    0   13]
 [ 133   17    1  248   13    5    6]
 [  51   27   19   20  201    1    3]
 [   8    1    0    9   10   11    0]
 [  10    2   16    4    4    0   39]]
Epoch 80
-------------------------------

batch:100    loss: 0.013453 lr: 0.0002839379950497238

batch:200    loss: 0.011552 lr: 0.0002839379950497238

batch:300    loss: 0.017908 lr: 0.0002839379950497238

batch:400    loss: 0.016477 lr: 0.0002839379950497238

batch:500    loss: 0.016865 lr: 0.0002839379950497238

batch:600    loss: 0.016124 lr: 0.0002839379950497238

batch:700    loss: 0.016515 lr: 0.0002839379950497238

batch:800    loss: 0.015633 lr: 0.0002839379950497238

Test Error: 
 Accuracy: 77.3%, Avg loss: 1.568769 

[[1137   65   21  110   20    0    6]
 [  64  793    9   23    9    1    1]
 [  57   16  352    4   16    0   16]
 [ 144   14    0  243   12    3    7]
 [  53   24   14   30  198    1    2]
 [  13    0    1    7    6   12    0]
 [  16    3   13    4    6    0   33]]
Epoch 81
-------------------------------

batch:100    loss: 0.010987 lr: 0.0002763932022500211

batch:200    loss: 0.010863 lr: 0.0002763932022500211

batch:300    loss: 0.010419 lr: 0.0002763932022500211

batch:400    loss: 0.010619 lr: 0.0002763932022500211

batch:500    loss: 0.011016 lr: 0.0002763932022500211

batch:600    loss: 0.011333 lr: 0.0002763932022500211

batch:700    loss: 0.010497 lr: 0.0002763932022500211

batch:800    loss: 0.010428 lr: 0.0002763932022500211

Test Error: 
 Accuracy: 78.5%, Avg loss: 1.577267 

[[1134   68   28  102   21    0    6]
 [  58  797   10   20   11    0    4]
 [  39   17  366    5   14    0   20]
 [ 135   21    1  243   12    4    7]
 [  48   19   17   18  214    4    2]
 [  12    0    1    7    6   13    0]
 [  11    3   12    3    4    0   42]]
Saved PyTorch Model State epoch is 80   correct = 78.48561050572785

Epoch 82
-------------------------------

batch:100    loss: 0.008629 lr: 0.00026916777029017535

batch:200    loss: 0.009645 lr: 0.00026916777029017535

batch:300    loss: 0.010570 lr: 0.00026916777029017535

batch:400    loss: 0.010237 lr: 0.00026916777029017535

batch:500    loss: 0.011376 lr: 0.00026916777029017535

batch:600    loss: 0.013371 lr: 0.00026916777029017535

batch:700    loss: 0.014035 lr: 0.00026916777029017535

batch:800    loss: 0.013459 lr: 0.00026916777029017535

Test Error: 
 Accuracy: 77.0%, Avg loss: 1.567640 

[[1137   65   27   83   35    0   12]
 [  47  794    8   30   16    0    5]
 [  43   20  346    4   24    0   24]
 [ 143   19    3  212   24    9   13]
 [  45   17   15   19  221    2    3]
 [  10    0    0    3   13   12    1]
 [  10    4   14    3    9    0   35]]
Epoch 83
-------------------------------

batch:100    loss: 0.014154 lr: 0.0002622688297991941

batch:200    loss: 0.016065 lr: 0.0002622688297991941

batch:300    loss: 0.013093 lr: 0.0002622688297991941

batch:400    loss: 0.013132 lr: 0.0002622688297991941

batch:500    loss: 0.012840 lr: 0.0002622688297991941

batch:600    loss: 0.013089 lr: 0.0002622688297991941

batch:700    loss: 0.012238 lr: 0.0002622688297991941

batch:800    loss: 0.012005 lr: 0.0002622688297991941

Test Error: 
 Accuracy: 77.7%, Avg loss: 1.607351 

[[1177   45   13   95   27    0    2]
 [  72  770   10   29   16    1    2]
 [  62   17  345    8   18    0   11]
 [ 155   17    1  226   15    5    4]
 [  55   16   11   18  218    4    0]
 [  13    0    0    5    8   13    0]
 [  16    3   13    3    6    1   33]]
Epoch 84
-------------------------------

batch:100    loss: 0.005737 lr: 0.00025570318919842253

batch:200    loss: 0.009157 lr: 0.00025570318919842253

batch:300    loss: 0.009279 lr: 0.00025570318919842253

batch:400    loss: 0.010209 lr: 0.00025570318919842253

batch:500    loss: 0.009825 lr: 0.00025570318919842253

batch:600    loss: 0.009722 lr: 0.00025570318919842253

batch:700    loss: 0.009444 lr: 0.00025570318919842253

batch:800    loss: 0.009192 lr: 0.00025570318919842253

Test Error: 
 Accuracy: 77.6%, Avg loss: 1.648053 

[[1139   65   21  102   22    1    9]
 [  62  794   11   24    6    1    2]
 [  49   20  354    7    9    0   22]
 [ 134   19    3  240   12    7    8]
 [  51   24   17   21  199    6    4]
 [  11    0    0    8    8   11    1]
 [  10    4   13    3    5    0   40]]
Epoch 85
-------------------------------

batch:100    loss: 0.009369 lr: 0.0002494773279824546

batch:200    loss: 0.011928 lr: 0.0002494773279824546

batch:300    loss: 0.010743 lr: 0.0002494773279824546

batch:400    loss: 0.009830 lr: 0.0002494773279824546

batch:500    loss: 0.010461 lr: 0.0002494773279824546

batch:600    loss: 0.010274 lr: 0.0002494773279824546

batch:700    loss: 0.009748 lr: 0.0002494773279824546

batch:800    loss: 0.010051 lr: 0.0002494773279824546

Test Error: 
 Accuracy: 77.9%, Avg loss: 1.594039 

[[1162   54   24   86   24    0    9]
 [  71  786   13   18   10    0    2]
 [  50   19  347    4   22    0   19]
 [ 144   21    2  228   15    7    6]
 [  52   19   12   21  214    2    2]
 [  13    1    0    6    7   12    0]
 [  10    2   11    6    6    0   40]]
Epoch 86
-------------------------------

batch:100    loss: 0.017103 lr: 0.00024359739032465288

batch:200    loss: 0.014620 lr: 0.00024359739032465288

batch:300    loss: 0.013761 lr: 0.00024359739032465288

batch:400    loss: 0.012997 lr: 0.00024359739032465288

batch:500    loss: 0.012100 lr: 0.00024359739032465288

batch:600    loss: 0.012064 lr: 0.00024359739032465288

batch:700    loss: 0.011738 lr: 0.00024359739032465288

batch:800    loss: 0.012362 lr: 0.00024359739032465288

Test Error: 
 Accuracy: 77.8%, Avg loss: 1.592066 

[[1131   67   27   94   30    1    9]
 [  56  794   15   23    8    0    4]
 [  34   16  366    6   15    0   24]
 [ 138   23    2  230   14    6   10]
 [  51   17   16   22  205    3    8]
 [   8    0    0   11    9   11    0]
 [   8    2   13    2    4    0   46]]
Epoch 87
-------------------------------

batch:100    loss: 0.009452 lr: 0.00023806917901359227

batch:200    loss: 0.008433 lr: 0.00023806917901359227

batch:300    loss: 0.008028 lr: 0.00023806917901359227

batch:400    loss: 0.008463 lr: 0.00023806917901359227

batch:500    loss: 0.008281 lr: 0.00023806917901359227

batch:600    loss: 0.007980 lr: 0.00023806917901359227

batch:700    loss: 0.009388 lr: 0.00023806917901359227

batch:800    loss: 0.010018 lr: 0.00023806917901359227

Test Error: 
 Accuracy: 78.0%, Avg loss: 1.611390 

[[1174   46   24   65   37    1   12]
 [  71  756   22   18   18    0   15]
 [  37   11  372    7   15    0   19]
 [ 153   15    1  217   19    5   13]
 [  50   12   17   17  216    3    7]
 [  10    0    0    6   11   12    0]
 [   8    2   12    2    5    0   46]]
Epoch 88
-------------------------------

batch:100    loss: 0.010088 lr: 0.00023289814972640767

batch:200    loss: 0.011320 lr: 0.00023289814972640767

batch:300    loss: 0.011158 lr: 0.00023289814972640767

batch:400    loss: 0.010836 lr: 0.00023289814972640767

batch:500    loss: 0.010028 lr: 0.00023289814972640767

batch:600    loss: 0.010035 lr: 0.00023289814972640767

batch:700    loss: 0.011106 lr: 0.00023289814972640767

batch:800    loss: 0.011664 lr: 0.00023289814972640767

Test Error: 
 Accuracy: 76.6%, Avg loss: 1.558448 

[[1089   57   28  131   37    2   15]
 [  60  770   18   28   13    1   10]
 [  32   19  362    7   20    0   21]
 [ 114   19    2  254   18   11    5]
 [  40   15   19   26  213    3    6]
 [   9    0    0    5   12   13    0]
 [   8    3   14    3    5    0   42]]
Epoch 89
-------------------------------

batch:100    loss: 0.007710 lr: 0.00022808940564469948

batch:200    loss: 0.006632 lr: 0.00022808940564469948

batch:300    loss: 0.007539 lr: 0.00022808940564469948

batch:400    loss: 0.007982 lr: 0.00022808940564469948

batch:500    loss: 0.007988 lr: 0.00022808940564469948

batch:600    loss: 0.008439 lr: 0.00022808940564469948

batch:700    loss: 0.008964 lr: 0.00022808940564469948

batch:800    loss: 0.008965 lr: 0.00022808940564469948

Test Error: 
 Accuracy: 78.0%, Avg loss: 1.633867 

[[1157   45   38   76   27    2   14]
 [  65  769   17   23   13    1   12]
 [  32   16  372    4   16    1   20]
 [ 144   14    3  226   18   11    7]
 [  51   15   18   19  213    3    3]
 [  12    0    0    3   12   12    0]
 [   8    2   16    3    5    0   41]]
Epoch 90
-------------------------------

batch:100    loss: 0.007356 lr: 0.00022364769241830983

batch:200    loss: 0.007375 lr: 0.00022364769241830983

batch:300    loss: 0.006911 lr: 0.00022364769241830983

batch:400    loss: 0.006861 lr: 0.00022364769241830983

batch:500    loss: 0.007453 lr: 0.00022364769241830983

batch:600    loss: 0.007656 lr: 0.00022364769241830983

batch:700    loss: 0.007631 lr: 0.00022364769241830983

batch:800    loss: 0.008199 lr: 0.00022364769241830983

Test Error: 
 Accuracy: 77.7%, Avg loss: 1.651717 

[[1141   58   26   85   37    2   10]
 [  71  778   14   11   19    0    7]
 [  43   14  361    4   19    0   20]
 [ 141   18    1  229   17    9    8]
 [  50   16   13   18  218    3    4]
 [  11    0    0    5   12   11    0]
 [  10    2   13    2    5    0   43]]
Epoch 91
-------------------------------

batch:100    loss: 0.006898 lr: 0.00021957739348193862

batch:200    loss: 0.007054 lr: 0.00021957739348193862

batch:300    loss: 0.006646 lr: 0.00021957739348193862

batch:400    loss: 0.006006 lr: 0.00021957739348193862

batch:500    loss: 0.005679 lr: 0.00021957739348193862

batch:600    loss: 0.005357 lr: 0.00021957739348193862

batch:700    loss: 0.005228 lr: 0.00021957739348193862

batch:800    loss: 0.005972 lr: 0.00021957739348193862

Test Error: 
 Accuracy: 78.5%, Avg loss: 1.643674 

[[1159   54   23   89   23    0   11]
 [  63  794   11   18    8    1    5]
 [  38   20  363    4   14    0   22]
 [ 138   21    1  236    7   10   10]
 [  48   19   16   23  206    2    8]
 [  11    0    0    7    8   12    1]
 [  11    4   13    2    4    0   41]]
Saved PyTorch Model State epoch is 90   correct = 78.5414920368818

Epoch 92
-------------------------------

batch:100    loss: 0.006921 lr: 0.00021588252572922286

batch:200    loss: 0.008768 lr: 0.00021588252572922286

batch:300    loss: 0.008367 lr: 0.00021588252572922286

batch:400    loss: 0.009417 lr: 0.00021588252572922286

batch:500    loss: 0.008973 lr: 0.00021588252572922286

batch:600    loss: 0.009447 lr: 0.00021588252572922286

batch:700    loss: 0.009394 lr: 0.00021588252572922286

batch:800    loss: 0.009096 lr: 0.00021588252572922286

Test Error: 
 Accuracy: 77.8%, Avg loss: 1.664330 

[[1137   67   27   93   25    0   10]
 [  55  793    8   26   14    0    4]
 [  42   20  362    6   15    0   16]
 [ 142   21    1  231   16    7    5]
 [  49   18   15   23  214    1    2]
 [  11    0    0    5   11   11    1]
 [  12    4   14    3    7    0   35]]
Epoch 93
-------------------------------

batch:100    loss: 0.002227 lr: 0.00021256673554854763

batch:200    loss: 0.005796 lr: 0.00021256673554854763

batch:300    loss: 0.006279 lr: 0.00021256673554854763

batch:400    loss: 0.008844 lr: 0.00021256673554854763

batch:500    loss: 0.009956 lr: 0.00021256673554854763

batch:600    loss: 0.009923 lr: 0.00021256673554854763

batch:700    loss: 0.009232 lr: 0.00021256673554854763

batch:800    loss: 0.009420 lr: 0.00021256673554854763

Test Error: 
 Accuracy: 77.8%, Avg loss: 1.636037 

[[1127   60   27  106   32    0    7]
 [  55  796   12   23   12    0    2]
 [  37   20  366    6   20    0   12]
 [ 130   21    1  244   16    5    6]
 [  49   21   18   24  205    2    3]
 [  12    0    0    6   10   11    0]
 [  11    5   14    3    5    0   37]]
Epoch 94
-------------------------------

batch:100    loss: 0.005427 lr: 0.0002096332952245011

batch:200    loss: 0.007094 lr: 0.0002096332952245011

batch:300    loss: 0.006743 lr: 0.0002096332952245011

batch:400    loss: 0.007156 lr: 0.0002096332952245011

batch:500    loss: 0.008086 lr: 0.0002096332952245011

batch:600    loss: 0.008167 lr: 0.0002096332952245011

batch:700    loss: 0.007614 lr: 0.0002096332952245011

batch:800    loss: 0.007452 lr: 0.0002096332952245011

Test Error: 
 Accuracy: 78.3%, Avg loss: 1.650823 

[[1170   47   23   87   24    0    8]
 [  73  777   12   19   15    0    4]
 [  39   19  366    5   17    0   15]
 [ 149   17    0  233   13    4    7]
 [  54   17   21   21  206    2    1]
 [  14    0    0    3   11   11    0]
 [  13    2   14    3    5    0   38]]
Epoch 95
-------------------------------

batch:100    loss: 0.003679 lr: 0.0002070850997085245

batch:200    loss: 0.004727 lr: 0.0002070850997085245

batch:300    loss: 0.005179 lr: 0.0002070850997085245

batch:400    loss: 0.005993 lr: 0.0002070850997085245

batch:500    loss: 0.006535 lr: 0.0002070850997085245

batch:600    loss: 0.007219 lr: 0.0002070850997085245

batch:700    loss: 0.007024 lr: 0.0002070850997085245

batch:800    loss: 0.007588 lr: 0.0002070850997085245

Test Error: 
 Accuracy: 78.0%, Avg loss: 1.672579 

[[1141   82   23   72   26    1   14]
 [  53  802   12   16   11    1    5]
 [  37   21  363    4   13    0   23]
 [ 139   25    1  223   15    7   13]
 [  51   18   16   18  208    2    9]
 [  13    0    0    3    8   14    1]
 [   6    4   15    4    4    0   42]]
Epoch 96
-------------------------------

batch:100    loss: 0.006023 lr: 0.00020492466376194498

batch:200    loss: 0.006206 lr: 0.00020492466376194498

batch:300    loss: 0.005963 lr: 0.00020492466376194498

batch:400    loss: 0.007313 lr: 0.00020492466376194498

batch:500    loss: 0.006777 lr: 0.00020492466376194498

batch:600    loss: 0.006866 lr: 0.00020492466376194498

batch:700    loss: 0.006378 lr: 0.00020492466376194498

batch:800    loss: 0.006194 lr: 0.00020492466376194498

Test Error: 
 Accuracy: 78.3%, Avg loss: 1.677483 

[[1179   56   25   72   19    0    8]
 [  69  780   16   18   13    1    3]
 [  37   17  371    3   18    0   15]
 [ 159   18    1  218   17    3    7]
 [  58   20   17   21  202    2    2]
 [  14    0    0    5    9   11    0]
 [   9    3   15    3    4    0   41]]
Epoch 97
-------------------------------

batch:100    loss: 0.006386 lr: 0.00020315411947420891

batch:200    loss: 0.007549 lr: 0.00020315411947420891

batch:300    loss: 0.006394 lr: 0.00020315411947420891

batch:400    loss: 0.007106 lr: 0.00020315411947420891

batch:500    loss: 0.007061 lr: 0.00020315411947420891

batch:600    loss: 0.006761 lr: 0.00020315411947420891

batch:700    loss: 0.007112 lr: 0.00020315411947420891

batch:800    loss: 0.006865 lr: 0.00020315411947420891

Test Error: 
 Accuracy: 77.5%, Avg loss: 1.728112 

[[1140   66   16  103   24    0   10]
 [  62  789    7   28   10    1    3]
 [  51   15  351    7   19    0   18]
 [ 139   18    0  234   15    8    9]
 [  49   17   15   26  208    3    4]
 [  11    0    0    7    9   12    0]
 [  11    3   13    5    5    0   38]]
Epoch 98
-------------------------------

batch:100    loss: 0.002893 lr: 0.00020177521415876802

batch:200    loss: 0.005096 lr: 0.00020177521415876802

batch:300    loss: 0.005991 lr: 0.00020177521415876802

batch:400    loss: 0.006220 lr: 0.00020177521415876802

batch:500    loss: 0.006479 lr: 0.00020177521415876802

batch:600    loss: 0.007910 lr: 0.00020177521415876802

batch:700    loss: 0.008440 lr: 0.00020177521415876802

batch:800    loss: 0.007780 lr: 0.00020177521415876802

Test Error: 
 Accuracy: 77.6%, Avg loss: 1.710971 

[[1169   49   14   93   24    0   10]
 [  78  772    9   19   13    1    8]
 [  48   14  353    4   20    1   21]
 [ 153   13    0  227   15    5   10]
 [  51   15   18   22  209    4    3]
 [   9    0    0    5   13   11    1]
 [  12    3   15    2    5    0   38]]
Epoch 99
-------------------------------

batch:100    loss: 0.006316 lr: 0.0002007893086286914

batch:200    loss: 0.004560 lr: 0.0002007893086286914

batch:300    loss: 0.005701 lr: 0.0002007893086286914

batch:400    loss: 0.004943 lr: 0.0002007893086286914

batch:500    loss: 0.004371 lr: 0.0002007893086286914

batch:600    loss: 0.004594 lr: 0.0002007893086286914

batch:700    loss: 0.005245 lr: 0.0002007893086286914

batch:800    loss: 0.005926 lr: 0.0002007893086286914

Test Error: 
 Accuracy: 78.1%, Avg loss: 1.732700 

[[1146   46   13  133   16    0    5]
 [  68  787    8   27    9    0    1]
 [  59   18  343    8   17    1   15]
 [ 125   15    0  270    6    2    5]
 [  48   19   15   35  199    0    6]
 [  13    0    0    6    5   14    1]
 [  13    3   12    5    5    0   37]]
Epoch 100
-------------------------------

batch:100    loss: 0.007750 lr: 0.00020019737585370736

batch:200    loss: 0.008099 lr: 0.00020019737585370736

batch:300    loss: 0.006531 lr: 0.00020019737585370736

batch:400    loss: 0.006327 lr: 0.00020019737585370736

batch:500    loss: 0.006980 lr: 0.00020019737585370736

batch:600    loss: 0.007211 lr: 0.00020019737585370736

batch:700    loss: 0.007272 lr: 0.00020019737585370736

batch:800    loss: 0.008096 lr: 0.00020019737585370736

Test Error: 
 Accuracy: 77.6%, Avg loss: 1.652173 

[[1175   52   13   93   21    2    3]
 [  67  780    6   31   11    1    4]
 [  63   18  327    6   30    0   17]
 [ 152   16    1  232   14    3    5]
 [  54   17    8   22  215    2    4]
 [  13    1    0    4    8   12    1]
 [  13    3   12    4    5    0   38]]
Done!

